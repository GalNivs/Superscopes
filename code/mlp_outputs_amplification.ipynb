{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5461d9f-9959-43b9-a408-c1e872d71010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic imports\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Utilities\n",
    "from general_utils import (\n",
    "  ModelAndTokenizer,\n",
    "  make_inputs,\n",
    "  decode_tokens,\n",
    ")\n",
    "from patchscopes_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a077dc8-31b7-4ad3-adbe-d169d6c2d602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galniv/patch_transformers/transformers-4.34.1/src/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/galniv/patch_transformers/transformers-4.34.1/src/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180fe1f429144ca98e0b187b567d5a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 5120)\n",
       "    (layers): ModuleList(\n",
       "      (0-39): 40 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (k_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (v_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (o_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=5120, out_features=13824, bias=False)\n",
       "          (up_proj): Linear(in_features=5120, out_features=13824, bias=False)\n",
       "          (down_proj): Linear(in_features=13824, out_features=5120, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5120, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the model\n",
    "model_to_hook = {\n",
    "    \"EleutherAI/pythia-12b\": set_hs_patch_hooks_neox,\n",
    "    \"meta-llama/Llama-2-13b-chat-hf\": set_hs_patch_hooks_llama,\n",
    "    \"./stable-vicuna-13b\": set_hs_patch_hooks_llama,\n",
    "    \"EleutherAI/gpt-j-6b\": set_hs_patch_hooks_gptj\n",
    "}\n",
    "\n",
    "CURRENT_LLM = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "\n",
    "model_name = CURRENT_LLM\n",
    "\n",
    "if \"13b\" in model_name or \"12b\" in model_name:\n",
    "    torch_dtype = torch.float16\n",
    "else:\n",
    "    torch_dtype = None\n",
    "\n",
    "my_device = torch.device(\"cuda:0\")\n",
    "\n",
    "mt = ModelAndTokenizer(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=False,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=my_device,\n",
    ")\n",
    "\n",
    "mt.set_hs_patch_hooks = model_to_hook[model_name]\n",
    "mt.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd6272cc-7b40-4540-8483-83a444e53873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_extract_intermediate_values(prompt):\n",
    "    \"\"\"\n",
    "    Running the model and generating intermediate representations in each layer for:\n",
    "    1. residuals pre-mlp\n",
    "    2. mlp outputs\n",
    "    3. hidden states\n",
    "    \"\"\"\n",
    "    store_hooks = []\n",
    "    residual_pre_mlp_cache_ = []\n",
    "    mlp_cache_ = []\n",
    "\n",
    "    input_ids = make_inputs(mt.tokenizer, [prompt], device=mt.device)\n",
    "\n",
    "    def store_mlp_hook(module, input, output):\n",
    "        residual_pre_mlp_cache_.append(input[0][0])\n",
    "        mlp_cache_.append(output[0])\n",
    "\n",
    "    for layer in mt.model.model.layers:\n",
    "        store_hooks.append(layer.mlp.register_forward_hook(store_mlp_hook))\n",
    "\n",
    "    generated = mt.model(**input_ids, output_hidden_states=True)\n",
    "\n",
    "    hs_cache_ = [\n",
    "        generated[\"hidden_states\"][layer + 1][0] for layer in range(mt.num_layers)\n",
    "    ]\n",
    "\n",
    "    remove_hooks(store_hooks)\n",
    "\n",
    "    return residual_pre_mlp_cache_, mlp_cache_, hs_cache_\n",
    "\n",
    "def patchscope_interpret(vec, target_layer=0):\n",
    "    \"\"\"Interpretation of vectors using Patchscopes technique.\"\"\"\n",
    "    target_prompt = \"Syria: Country in the Middle East, Leonardo DiCaprio: American actor, Samsung: South Korean multinational major appliance and consumer electronics corporation, x\"\n",
    "    \n",
    "    # last token within target prompt\n",
    "    target_idx = -1\n",
    "\n",
    "    patch_config = {\n",
    "        target_layer: [(target_idx, vec)]\n",
    "    }\n",
    "\n",
    "    patch_hooks = mt.set_hs_patch_hooks(\n",
    "        mt.model, patch_config, module=\"hs\", patch_input=False, generation_mode=True,\n",
    "    )\n",
    "\n",
    "    inp = make_inputs(mt.tokenizer, [target_prompt], device=mt.device)\n",
    "\n",
    "    seq_len = len(inp[\"input_ids\"][0])\n",
    "    max_token_to_produce = 10\n",
    "    output_toks = mt.model.generate(\n",
    "        inp[\"input_ids\"],\n",
    "        max_length=seq_len + max_token_to_produce,\n",
    "        pad_token_id=mt.model.generation_config.eos_token_id,\n",
    "    )\n",
    "    \n",
    "    remove_hooks(patch_hooks)\n",
    "\n",
    "    generations_patched =  mt.tokenizer.decode(output_toks[0][len(inp[\"input_ids\"][0]):])\n",
    "    \n",
    "    return generations_patched\n",
    "\n",
    "def find_token_id(prompt, token):\n",
    "    \"\"\"finding the offset of a specific token within a prompt.\"\"\"\n",
    "    inp = make_inputs(mt.tokenizer, [prompt], device=mt.device)\n",
    "    decoded = decode_tokens(mt.tokenizer, inp['input_ids'])[0]\n",
    "\n",
    "    return decoded.index(token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b9677-f8e6-4f8f-88e3-6132fc855e19",
   "metadata": {},
   "source": [
    "# MLP Interpretation Experiment\n",
    "We show the following steps performed on each example:\n",
    "1. Running the LLM model to generate residual pre-MLP, MLP output and hidden state representations for each layer.\n",
    "2. Using the hidden states, we find the layer in which the MLP output provides enough contextualization for the hidden state to interpret as the context of the sentence. In this part we will also observe the MLP outputs yielding meaningless results as a whole.\n",
    "4. Obtaining the meaning of the MLP outputs using Superscopes amplification, starting from the contextualized layer or even a layer prior in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a52dcd-d255-42a5-acfe-dc22d0a57c13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 1\n",
      "\n",
      "Residual pre-MLP result: : Country in the United Kingdom, Celine D\n",
      "\n",
      "MLP Output result: : Aramaic language, which was the language\n",
      "\n",
      "Hidden State result: : Country in Great Britain, Tesla:\n",
      "\n",
      "\n",
      "Layer 2\n",
      "\n",
      "Residual pre-MLP result: : Country in the United Kingdom, Jake Gy\n",
      "\n",
      "MLP Output result: lywood: Informal term for the Hollywood film industry\n",
      "\n",
      "Hidden State result: : Country in the United Kingdom, United Nations:\n",
      "\n",
      "\n",
      "Layer 3\n",
      "\n",
      "Residual pre-MLP result: : Country in the United Kingdom, Zara:\n",
      "\n",
      "MLP Output result: , J.J. Watt: American football\n",
      "\n",
      "Hidden State result: : Title of honorific for the British royal family\n",
      "\n",
      "\n",
      "Layer 4\n",
      "\n",
      "Residual pre-MLP result: : A title of nobility, etc.\n",
      "\n",
      "\n",
      "MLP Output result: , Tesla: American electric vehicle and clean\n",
      "\n",
      "Hidden State result: : Title of honorific for the wife of a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test number 1 - (\"Diana, Princess of Wales\", \"Wales\") MLP interpretation\n",
    "residual_pre_mlp_cache, mlp_outputs_cache, hs_cache = generate_and_extract_intermediate_values(\"Diana, Princess of Wales\")\n",
    "\n",
    "source_position = find_token_id(\"Diana, Princess of Wales\", \"Wales\")\n",
    "\n",
    "for layer in range(1, 5):\n",
    "    print()\n",
    "    print(f\"Layer {layer}\")\n",
    "    print()\n",
    "    print(f\"Residual pre-MLP result: {patchscope_interpret(residual_pre_mlp_cache[layer][source_position])}\")\n",
    "    print()\n",
    "    print(f\"MLP Output result: {patchscope_interpret(mlp_outputs_cache[layer][source_position])}\")\n",
    "    print()\n",
    "    print(f\"Hidden State result: {patchscope_interpret(hs_cache[layer][source_position])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76bcfa8-d7b8-4547-9c75-1f6b9be65b4c",
   "metadata": {},
   "source": [
    "### Residual pre-MLP, MLP Outputs, Hidden State - Results Explanation\n",
    "\n",
    "As one can simply see, the token resembles into a royalty-related contextualized token after layer 3 (inclusive).\n",
    "\n",
    "We can also see that the MLP Output has no meaning here at all, in the following part we are going to amplify the MLP output and extract its meaning, starting from a layer prior to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc8c8701-bdcd-48c2-9370-24295f229c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 2\n",
      "\n",
      "MLP Output (Amp=3) result: : The fourth letter of the alphabet, Pink\n",
      "\n",
      "MLP Output (Amp=6) result: : English county, Adele: British singer\n",
      "\n",
      "MLP Output (Amp=9) result: : British prince, Harry: American singer-song\n",
      "\n",
      "MLP Output (Amp=12) result: : A letter that is used to form words,\n",
      "\n",
      "MLP Output (Amp=15) result: : A prince of the United Kingdom, Mery\n",
      "\n",
      "\n",
      "Layer 3\n",
      "\n",
      "MLP Output (Amp=3) result: : British singer-songwriter and actress, G\n",
      "\n",
      "MLP Output (Amp=6) result: : English singer-songwriter.\n",
      "\n",
      "Th\n",
      "\n",
      "MLP Output (Amp=9) result: : Australian rock band, and Ebola:\n",
      "\n",
      "MLP Output (Amp=12) result: : Prime Minister of Australia, BTS: South\n",
      "\n",
      "MLP Output (Amp=15) result: : A colloquial term for a susp\n",
      "\n",
      "\n",
      "Layer 4\n",
      "\n",
      "MLP Output (Amp=3) result: : Title of respect for a woman, particularly a\n",
      "\n",
      "MLP Output (Amp=6) result: : Title of honorific address for a married woman\n",
      "\n",
      "MLP Output (Amp=9) result: : A title of honorific, typically used for\n",
      "\n",
      "MLP Output (Amp=12) result: : The wife of a king or queen.\n",
      "\n",
      "\n",
      "MLP Output (Amp=15) result: , and the 2016 Summer Olympics\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "realization_layer = 3\n",
    "\n",
    "for layer in range(realization_layer - 1, realization_layer + 2):\n",
    "    print(f\"Layer {layer}\")\n",
    "    for amp in range(3, 18, 3):\n",
    "        print()\n",
    "        print(f\"MLP Output (Amp={amp}) result: {patchscope_interpret(mlp_outputs_cache[layer][source_position] * amp, target_layer=layer)}\")\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f1eeb-f269-48c7-a2c6-3df7fdac2156",
   "metadata": {},
   "source": [
    "### Results Analysis\n",
    "As one can simply see, we get british and royalty related results starting from layer 2, obtaining our objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c657fe55-7bc2-4817-b6ce-25908d040a3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 1\n",
      "\n",
      "Residual pre-MLP result: : Time period after present, M&M'\n",
      "\n",
      "MLP Output result: : Time period after the present, The Reven\n",
      "\n",
      "Hidden State result: : Ahead of one's time, innov\n",
      "\n",
      "\n",
      "Layer 2\n",
      "\n",
      "Residual pre-MLP result: : concept of time, Glossary of religious\n",
      "\n",
      "MLP Output result: : These are just a few examples of what a\n",
      "\n",
      "Hidden State result: : Science fiction film trilogy, and the\n",
      "\n",
      "\n",
      "Layer 3\n",
      "\n",
      "Residual pre-MLP result: : 2015 science fiction film directed\n",
      "\n",
      "MLP Output result: : The word or phrase that best fits each blank\n",
      "\n",
      "Hidden State result: : 1985 science fiction film,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test number 2 - \"Back to the Future\" - \"Future\" token MLP interpretation\n",
    "residual_pre_mlp_cache, mlp_outputs_cache, hs_cache = generate_and_extract_intermediate_values(\"Back to the Future\")\n",
    "\n",
    "source_position = find_token_id(\"Back to the Future\", \"Future\")\n",
    "\n",
    "for layer in range(1, 4):\n",
    "    print()\n",
    "    print(f\"Layer {layer}\")\n",
    "    print()\n",
    "    print(f\"Residual pre-MLP result: {patchscope_interpret(residual_pre_mlp_cache[layer][source_position])}\")\n",
    "    print()\n",
    "    print(f\"MLP Output result: {patchscope_interpret(mlp_outputs_cache[layer][source_position])}\")\n",
    "    print()\n",
    "    print(f\"Hidden State result: {patchscope_interpret(hs_cache[layer][source_position])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0986e49-4ac7-42fc-952b-a647f1e5f352",
   "metadata": {},
   "source": [
    "### Residual pre-MLP, MLP Outputs, Hidden State - Results Explanation\n",
    "\n",
    "As one can simply see, the token resembles into a science-fiction movie contextualized token after layer 2 (inclusive).\n",
    "\n",
    "In the following part we are going to amplify the MLP output and extract its meaning, starting from a layer prior to 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a737a24-63c9-4637-9d4d-8e020b3070e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1\n",
      "\n",
      "MLP Output (Amp=3) result: : Time period after the present, The Reven\n",
      "\n",
      "MLP Output (Amp=6) result: : Time period after present, The Revenant\n",
      "\n",
      "MLP Output (Amp=9) result: : A time period after the present, Nost\n",
      "\n",
      "MLP Output (Amp=12) result: : Time period after the present, The Reven\n",
      "\n",
      "MLP Output (Amp=15) result: : A period of time coming after the present,\n",
      "\n",
      "\n",
      "Layer 2\n",
      "\n",
      "MLP Output (Amp=3) result: : 2015 film starring Di\n",
      "\n",
      "MLP Output (Amp=6) result: : 2006 science fiction film directed\n",
      "\n",
      "MLP Output (Amp=9) result: : 1985 film, The Mart\n",
      "\n",
      "MLP Output (Amp=12) result: : 1997 American science fiction film\n",
      "\n",
      "MLP Output (Amp=15) result: : 1997 film trilogy\n",
      "\n",
      "\n",
      "Layer 3\n",
      "\n",
      "MLP Output (Amp=3) result: : 2009 science fiction film directed\n",
      "\n",
      "MLP Output (Amp=6) result: : American rock band, and Pixar:\n",
      "\n",
      "MLP Output (Amp=9) result: : 2004 science fiction film directed\n",
      "\n",
      "MLP Output (Amp=12) result: : 1995 science fiction film directed\n",
      "\n",
      "MLP Output (Amp=15) result: : 1995 science fiction film directed\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "realization_layer = 2\n",
    "\n",
    "for layer in range(realization_layer - 1, realization_layer + 2):\n",
    "    print(f\"Layer {layer}\")\n",
    "    for amp in range(3, 18, 3):\n",
    "        print()\n",
    "        print(f\"MLP Output (Amp={amp}) result: {patchscope_interpret(mlp_outputs_cache[layer][source_position] * amp, target_layer=layer)}\")\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ef9f96-87d0-4bef-ad3d-65331bb34386",
   "metadata": {},
   "source": [
    "### Results Analysis\n",
    "As one can simply see, we get science fiction movie related results starting from layer 2, obtaining our objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3fa1164-2215-4881-80a7-449d0ef4a834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 2\n",
      "\n",
      "Residual pre-MLP result: : To be alive, Nokia: Finn\n",
      "\n",
      "MLP Output result: : shortened form of the word \"privile\n",
      "\n",
      "Hidden State result: Aid: A charity single recorded by a\n",
      "\n",
      "\n",
      "Layer 3\n",
      "\n",
      "Residual pre-MLP result: : A live television show, Oscar: Award given\n",
      "\n",
      "MLP Output result: ater: a large, deep hollow in the\n",
      "\n",
      "Hidden State result: : American sketch comedy and variety show, Dway\n",
      "\n",
      "\n",
      "Layer 4\n",
      "\n",
      "Residual pre-MLP result: : These are just a few examples of things that\n",
      "\n",
      "MLP Output result: : What do these three things have in common?\n",
      "\n",
      "Hidden State result: : American sketch comedy and variety show, Spon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test number 3 - \"Saturday Night Live\" - \"Live\" token MLP interpretation\n",
    "residual_pre_mlp_cache, mlp_outputs_cache, hs_cache = generate_and_extract_intermediate_values(\"Saturday Night Live\")\n",
    "\n",
    "source_position = find_token_id(\"Saturday Night Live\", \"Live\")\n",
    "\n",
    "for layer in range(2, 5):\n",
    "    print()\n",
    "    print(f\"Layer {layer}\")\n",
    "    print()\n",
    "    print(f\"Residual pre-MLP result: {patchscope_interpret(residual_pre_mlp_cache[layer][source_position])}\")\n",
    "    print()\n",
    "    print(f\"MLP Output result: {patchscope_interpret(mlp_outputs_cache[layer][source_position])}\")\n",
    "    print()\n",
    "    print(f\"Hidden State result: {patchscope_interpret(hs_cache[layer][source_position])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc95eb2c-9204-4f1c-b283-49d95f6d20aa",
   "metadata": {},
   "source": [
    "### Residual pre-MLP, MLP Outputs, Hidden State - Results Explanation\n",
    "\n",
    "As one can simply see, the token resembles into an American sketch comedy contextualized token after layer 3 (inclusive).\n",
    "\n",
    "In the following part we are going to amplify the MLP output and extract its meaning, starting from a layer prior to 3.\n",
    "\n",
    "Please note that all MLP outputs yielded nonsense.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91cd6c86-d426-4dd6-aa01-780fa96a38e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 2\n",
      "\n",
      "MLP Output (Amp=3) result: : A live television variety show, Titanic\n",
      "\n",
      "MLP Output (Amp=6) result: : type of television programming, Eminem:\n",
      "\n",
      "MLP Output (Amp=9) result: : Social media platform, Wakanda: F\n",
      "\n",
      "MLP Output (Amp=12) result: : a popular video-sharing platform, The\n",
      "\n",
      "MLP Output (Amp=15) result: : A live television variety show, The Lion King\n",
      "\n",
      "\n",
      "Layer 3\n",
      "\n",
      "MLP Output (Amp=3) result: , Tesla: American electric vehicle and clean\n",
      "\n",
      "MLP Output (Amp=6) result: , and Instagram: photo and video-sh\n",
      "\n",
      "MLP Output (Amp=9) result: , Meryl Streep: American actress\n",
      "\n",
      "MLP Output (Amp=12) result: : What do these three things have in common?\n",
      "\n",
      "MLP Output (Amp=15) result: , Nike: American multinational corporation\n",
      "\n",
      "\n",
      "Layer 4\n",
      "\n",
      "MLP Output (Amp=3) result: , and Easter: Christian holiday that celebr\n",
      "\n",
      "MLP Output (Amp=6) result: :\n",
      "\n",
      "* Leonardo DiCaprio is\n",
      "\n",
      "MLP Output (Amp=9) result: : Sketch comedy television series, and more\n",
      "\n",
      "\n",
      "MLP Output (Amp=12) result: : Satirical comedy, The Lion King:\n",
      "\n",
      "MLP Output (Amp=15) result: : These are just a few examples of words that\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "realization_layer = 3\n",
    "\n",
    "for layer in range(realization_layer - 1, realization_layer + 2):\n",
    "    print(f\"Layer {layer}\")\n",
    "    for amp in range(3, 18, 3):\n",
    "        print()\n",
    "        print(f\"MLP Output (Amp={amp}) result: {patchscope_interpret(mlp_outputs_cache[layer][source_position] * amp, target_layer=0)}\")\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2200a6e1-87ed-4c7a-9a31-ed863c29fda6",
   "metadata": {},
   "source": [
    "### Results Analysis\n",
    "As one can simply see, we get television, performance and American related results starting from layer 2, obtaining our objective.\n",
    "Please also note that Layer 4 amplified by 9 even yielded the entire context of the sentence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
