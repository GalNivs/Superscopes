{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a669c26f-ddd2-4b4f-a797-4c1f1dfb8358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic imports\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Utilities\n",
    "from general_utils import (\n",
    "  ModelAndTokenizer,\n",
    "  make_inputs,\n",
    "  decode_tokens,\n",
    ")\n",
    "from patchscopes_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d661a14c-fda2-4e89-999c-29c192a3bed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galniv/patch_transformers/transformers-4.34.1/src/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/galniv/patch_transformers/transformers-4.34.1/src/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e833f2fd7c94d9f932c64acb7a7427e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 5120)\n",
       "    (layers): ModuleList(\n",
       "      (0-39): 40 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (k_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (v_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (o_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=5120, out_features=13824, bias=False)\n",
       "          (up_proj): Linear(in_features=5120, out_features=13824, bias=False)\n",
       "          (down_proj): Linear(in_features=13824, out_features=5120, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5120, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the model\n",
    "model_to_hook = {\n",
    "    \"EleutherAI/pythia-12b\": set_hs_patch_hooks_neox,\n",
    "    \"meta-llama/Llama-2-13b-chat-hf\": set_hs_patch_hooks_llama,\n",
    "    \"./stable-vicuna-13b\": set_hs_patch_hooks_llama,\n",
    "    \"EleutherAI/gpt-j-6b\": set_hs_patch_hooks_gptj\n",
    "}\n",
    "\n",
    "CURRENT_LLM = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "\n",
    "model_name = CURRENT_LLM\n",
    "\n",
    "if \"13b\" in model_name or \"12b\" in model_name:\n",
    "    torch_dtype = torch.float16\n",
    "else:\n",
    "    torch_dtype = None\n",
    "\n",
    "my_device = torch.device(\"cuda:0\")\n",
    "\n",
    "mt = ModelAndTokenizer(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=False,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=my_device,\n",
    ")\n",
    "\n",
    "mt.set_hs_patch_hooks = model_to_hook[model_name]\n",
    "mt.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7e0f2a-5545-4fd8-8be9-8a2e9c0a2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_extract_hidden_states(prompt):\n",
    "    \"\"\"\n",
    "    Running the model and generating intermediate representations in each layer for the hidden states.\n",
    "    \"\"\"\n",
    "    input_ids = make_inputs(mt.tokenizer, [prompt], device=mt.device)\n",
    "    \n",
    "    generated = mt.model(**input_ids, output_hidden_states=True)\n",
    "\n",
    "    hs_cache_ = [\n",
    "        generated[\"hidden_states\"][layer + 1][0] for layer in range(mt.num_layers)\n",
    "    ]\n",
    "\n",
    "    return hs_cache_\n",
    "\n",
    "def patchscope_interpret(vec, target_layer=0):\n",
    "    \"\"\"Interpretation of vectors using Patchscopes technique.\"\"\"\n",
    "    target_prompt = \"Syria: Country in the Middle East, Leonardo DiCaprio: American actor, Samsung: South Korean multinational major appliance and consumer electronics corporation, x\"\n",
    "    \n",
    "    # last token within target prompt\n",
    "    target_idx = -1\n",
    "\n",
    "    patch_config = {\n",
    "        target_layer: [(target_idx, vec)]\n",
    "    }\n",
    "\n",
    "    patch_hooks = mt.set_hs_patch_hooks(\n",
    "        mt.model, patch_config, module=\"hs\", patch_input=False, generation_mode=True,\n",
    "    )\n",
    "\n",
    "    inp = make_inputs(mt.tokenizer, [target_prompt], device=mt.device)\n",
    "\n",
    "    seq_len = len(inp[\"input_ids\"][0])\n",
    "    max_token_to_produce = 10\n",
    "    output_toks = mt.model.generate(\n",
    "        inp[\"input_ids\"],\n",
    "        max_length=seq_len + max_token_to_produce,\n",
    "        pad_token_id=mt.model.generation_config.eos_token_id,\n",
    "    )\n",
    "    \n",
    "    remove_hooks(patch_hooks)\n",
    "\n",
    "    generations_patched =  mt.tokenizer.decode(output_toks[0][len(inp[\"input_ids\"][0]):])\n",
    "    \n",
    "    return generations_patched\n",
    "\n",
    "def find_token_id(prompt, token):\n",
    "    \"\"\"finding the offset of a specific token within a prompt.\"\"\"\n",
    "    inp = make_inputs(mt.tokenizer, [prompt], device=mt.device)\n",
    "    decoded = decode_tokens(mt.tokenizer, inp['input_ids'])[0]\n",
    "\n",
    "    return decoded.index(token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec829e2-e8c8-41cb-9a1a-d158c53af068",
   "metadata": {},
   "source": [
    "# Hidden States Interpretation Experiment\n",
    "\n",
    "This experiment comes to show how some hidden states become interpretable when they are amplified.\n",
    "For each example in this experiment we are going to show the following:\n",
    "1. Locate the first layer to become interpretable as the meaning of the sentence.\n",
    "2. Use Superscopes amplification to interpret a layer prior.\n",
    "\n",
    "We show that this methodology works in a lot of scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3d2abb1-e086-4f51-be92-f4c735e4f89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 4\n",
      "\n",
      "Hidden State result: Barack Obama: 44th President\n",
      "\n",
      "\n",
      "Layer 5\n",
      "\n",
      "Hidden State result: Barack Obama: American politician, 4\n",
      "\n",
      "\n",
      "Layer 6\n",
      "\n",
      "Hidden State result: : Ancient Greek king of Macedon,\n",
      "\n",
      "\n",
      "Layer 7\n",
      "\n",
      "Hidden State result: Wall Street: Street in Lower Manhattan, New\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test number 1 - \"Alexander the Great\" - \"Great\" token hidden state interpretation\n",
    "hs_cache = generate_and_extract_hidden_states(\"Alexander the Great\")\n",
    "\n",
    "source_position = find_token_id(\"Alexander the Great\", \"Great\")\n",
    "\n",
    "for layer in range(4, 8):\n",
    "    print()\n",
    "    print(f\"Layer {layer}\")\n",
    "    print()\n",
    "    print(f\"Hidden State result: {patchscope_interpret(hs_cache[layer][source_position])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7308fe8c-a09c-4767-bcb9-64961163f7a1",
   "metadata": {},
   "source": [
    "### Hidden States results explanation\n",
    "As one can simply see, hidden state of \"Great\" is contextualized as Alexander the Great in Layer 6.\n",
    "\n",
    "Next we will try to amplify layers beforehand and obtain their meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "337fe416-0127-49a5-8585-fe401e8bd8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 4\n",
      "\n",
      "Hidden State result (amp=2): Barack Obama: 44th President\n",
      "\n",
      "\n",
      "Hidden State result (amp=3): : Ancient Greek king, The Great Wall of\n",
      "\n",
      "\n",
      "Hidden State result (amp=4): Wall Street: Street in New York City's\n",
      "\n",
      "\n",
      "Hidden State result (amp=5): Wall Street: Street in Lower Manhattan, New\n",
      "\n",
      "\n",
      "Hidden State result (amp=6): Wall Street: Financial district in Lower Manh\n",
      "\n",
      "\n",
      "Layer 5\n",
      "\n",
      "Hidden State result (amp=2): Wall Street: Financial district in Lower Manh\n",
      "\n",
      "\n",
      "Hidden State result (amp=3): : The Macedonian king who conquered a\n",
      "\n",
      "\n",
      "Hidden State result (amp=4): : Which of these is NOT a country?\n",
      "\n",
      "\n",
      "\n",
      "Hidden State result (amp=5): : These are just a few examples of what?\n",
      "\n",
      "\n",
      "Hidden State result (amp=6): : What do these three things have in common?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer in range(4, 6):\n",
    "    print()\n",
    "    print(f\"Layer {layer}\")\n",
    "    for amp in range(2, 7, 1):\n",
    "        print()\n",
    "        print(f\"Hidden State result (amp={amp}): {patchscope_interpret(hs_cache[layer][source_position] * amp)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1939d12-8744-4060-ad03-a1db64f1f1fd",
   "metadata": {},
   "source": [
    "### Hidden States Amplification - Results Analysis\n",
    "We successfully interpreted the meaning \"Alexander the Great\" from layers 4 and 5, obtaining the contextualized meaning from 2 layers prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "afac65c4-c954-48a6-85bd-29cd1a919dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 2\n",
      "\n",
      "Hidden State result: : type of vegetable, Yellowstone National\n",
      "\n",
      "\n",
      "Layer 3\n",
      "\n",
      "Hidden State result: : A type of pepper, Gmail:\n",
      "\n",
      "\n",
      "Layer 4\n",
      "\n",
      "Hidden State result: : American rock band, Tesla: American\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test number 3 - \"Red Hot Chili Peppers\" - \"ppers\" token hidden state interpretation\n",
    "hs_cache = generate_and_extract_hidden_states(\"Red Hot Chili Peppers\")\n",
    "\n",
    "source_position = find_token_id(\"Red Hot Chili Peppers\", \"ppers\")\n",
    "\n",
    "for layer in range(2, 5):\n",
    "    print()\n",
    "    print(f\"Layer {layer}\")\n",
    "    print()\n",
    "    print(f\"Hidden State result: {patchscope_interpret(hs_cache[layer][source_position])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13826b5-cd4c-4ceb-ad08-d336115bf887",
   "metadata": {},
   "source": [
    "### Hidden States results explanation\n",
    "The hidden state of \"ppers\" is contextualized as the American rock band starting from Layer 4.\n",
    "\n",
    "Next we will try to amplify the layer beforehand and obtain its meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "318bbc81-1d20-439c-b7d5-76bba5d681a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 3\n",
      "\n",
      "Hidden State result (amp=1.3): : A type of vegetable, Dracula\n",
      "\n",
      "\n",
      "Hidden State result (amp=1.5): : The band, Titanic: The ship\n",
      "\n",
      "\n",
      "Hidden State result (amp=1.7): : Plant of the capsicum genus, Ebol\n",
      "\n",
      "\n",
      "Hidden State result (amp=1.9): : What do these three things have in common?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer in range(3, 4):\n",
    "    print()\n",
    "    print(f\"Layer {layer}\")\n",
    "    for amp in [1.3, 1.5, 1.7, 1.9]:\n",
    "        print()\n",
    "        print(f\"Hidden State result (amp={amp}): {patchscope_interpret(hs_cache[layer][source_position] * amp)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a78b2f9-e1d1-47d9-a266-467e2a3b74c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 3\n",
      "\n",
      "Hidden State result (amp=1.3): : Type of vegetable, The Beatles:\n",
      "\n",
      "\n",
      "Hidden State result (amp=1.5): : Rock band, and more.\n",
      "\n",
      "S\n",
      "\n",
      "\n",
      "Hidden State result (amp=1.7): : They all have something in common. What is\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer in range(3, 4):\n",
    "    print()\n",
    "    print(f\"Layer {layer}\")\n",
    "    for amp in [1.3, 1.5, 1.7]:\n",
    "        print()\n",
    "        print(f\"Hidden State result (amp={amp}): {patchscope_interpret(hs_cache[layer][source_position] * amp)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269b9214-d053-435c-a073-989b45a67ef4",
   "metadata": {},
   "source": [
    "### Hidden States Amplification - Results Analysis\n",
    "We successfully interpreted the meaning \"Rock band\" from layer 3, obtaining the contextualized meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "052204a1-854b-4532-8c9c-a11ad6e53023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 9\n",
      "\n",
      "Hidden State result: :\n",
      "\n",
      "Syria: A country in\n",
      "\n",
      "\n",
      "Layer 10\n",
      "\n",
      "Hidden State result: : British rock band, Honey Boo Bo\n",
      "\n",
      "\n",
      "Layer 11\n",
      "\n",
      "Hidden State result: : These are just a few examples of the many\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test number 2 - \"Florence and the Machine\" - \"Machine\" token hidden state interpretation\n",
    "hs_cache = generate_and_extract_hidden_states(\"Florence and the Machine\")\n",
    "\n",
    "source_position = find_token_id(\"Florence and the Machine\", \"Machine\")\n",
    "\n",
    "for layer in range(9, 12):\n",
    "    print()\n",
    "    print(f\"Layer {layer}\")\n",
    "    print()\n",
    "    print(f\"Hidden State result: {patchscope_interpret(hs_cache[layer][source_position])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8cfb84-199d-4055-920b-d359ea06f806",
   "metadata": {},
   "source": [
    "### Hidden States results explanation\n",
    "The hidden state of \"Machine\" is contextualized as a British band starting from Layer 10.\n",
    "\n",
    "Next we will try to amplify the layers beforehand and obtain their meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b5af24b-3186-41a5-b3e2-7d6e766b6e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 9\n",
      "\n",
      "Hidden State result (amp=3): : These are just a few examples of words that\n",
      "\n",
      "\n",
      "Hidden State result (amp=6): .\n",
      "\n",
      "Syria is a country in\n",
      "\n",
      "\n",
      "Hidden State result (amp=9): â€™s new album, and more\n",
      "Good morning\n",
      "\n",
      "\n",
      "Hidden State result (amp=12): is a British rock band, and The Reven\n",
      "\n",
      "\n",
      "Hidden State result (amp=15): , and The Great Gatsby: Novel\n",
      "\n",
      "\n",
      "Hidden State result (amp=18): to name a few.\n",
      "\n",
      "The word \"\n",
      "\n",
      "\n",
      "Hidden State result (amp=21): 's new album \"Hair, Hunt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer in range(9, 10):\n",
    "    print()\n",
    "    print(f\"Layer {layer}\")\n",
    "    for amp in range(3, 24, 3):\n",
    "        print()\n",
    "        print(f\"Hidden State result (amp={amp}): {patchscope_interpret(hs_cache[layer][source_position] * amp)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50dda93-434d-4fc7-a988-6510e088a8b3",
   "metadata": {},
   "source": [
    "### Hidden States Amplification - Results Analysis\n",
    "We successfully interpreted the meaning \"British rock band\" from layer 9, obtaining the contextualized meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "057cf95f-ad74-40c8-8cd0-87efec1678ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 7\n",
      "\n",
      "Hidden State result (amp=3): :\n",
      "\n",
      "Syria: A country in\n",
      "\n",
      "\n",
      "Hidden State result (amp=6): : These are just a few examples of things that\n",
      "\n",
      "\n",
      "Hidden State result (amp=9): toilet paper: Product used for cleaning\n",
      "\n",
      "\n",
      "Hidden State result (amp=12): .\n",
      "\n",
      "In the following list, the third\n",
      "\n",
      "\n",
      "Hidden State result (amp=15): song \"Someone Like You\" by Ade\n",
      "\n",
      "\n",
      "Hidden State result (amp=18): to name a few.\n",
      "\n",
      "These are\n",
      "\n",
      "\n",
      "Hidden State result (amp=21): ___: British singer-songwriter, and\n",
      "\n",
      "\n",
      "Layer 8\n",
      "\n",
      "Hidden State result (amp=3): : These are just a few examples of the many\n",
      "\n",
      "\n",
      "Hidden State result (amp=6): : These three things may not seem related, but\n",
      "\n",
      "\n",
      "Hidden State result (amp=9): , Pink Floyd: English rock band,\n",
      "\n",
      "\n",
      "Hidden State result (amp=12): to name a few.\n",
      "\n",
      "Answer:\n",
      "\n",
      "\n",
      "\n",
      "Hidden State result (amp=15): , and Fear and Loathing in Las\n",
      "\n",
      "\n",
      "Hidden State result (amp=18): , and the FIFA World Cup: International soccer\n",
      "\n",
      "\n",
      "Hidden State result (amp=21): 's new album \"Everything Now\" is\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer in range(7, 9):\n",
    "    print()\n",
    "    print(f\"Layer {layer}\")\n",
    "    for amp in range(3, 24, 3):\n",
    "        print()\n",
    "        print(f\"Hidden State result (amp={amp}): {patchscope_interpret(hs_cache[layer][source_position] * amp)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb61859-9854-4e98-bb74-4729048d212d",
   "metadata": {},
   "source": [
    "### Hidden States Amplification - Results Analysis\n",
    "When looking at layers prior to 9, we can see music and British culture contextualization which was not obtained before hand.\n",
    "\n",
    "We even see the token at layer 7 interpreted as a \"British singer-songwriter\" when multiplied by a big multiplier, which is almost the correct meaning of the entire sentence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
